components:
  source1:
    type: batchSource
    format: json
    options: { a: b, path: 'there/file.json' }
    encodedAs: { type: STRING }
  source2:
    type: streamSource
    format: kafka
    options: { a: b, path: 'there/file.json' }
    encodedAs: { schema: bean, ofClass: "a.b.C" }
  txTest:
    type: encode
    using: source1
    encodedAs: { schema: tuple, of: [{ type: STRING }, { type: BINARY }] }
  tx:
    type: encode
    using: source1
    encodedAs: { type: INT }
  tx2:
    type: sql
    using: [ tx, source2 ]
    sql: "select * from tx as t join fileIn2 as f on t.id = f.id"

sinks:
  out1:
    type: batch
    format: parquet
    options: { path: 'abc' }
    mode: OVERWRITE
  out2:
    type: stream
    name: queryNameHere
    format: kafka
    options: { path: 'abc' }
    trigger: { milliseconds: 60 }
    mode: APPEND
  out3:
    type: foreachBatch
    name: out3
    trigger: { milliseconds: 60 }
    mode: APPEND
    batches:
      - source: src
        components:
          tx: { type: encode, using: src, as: { type: INT } }
        sink: { type: batch, format: parquet, options: { path: 'abc' }, mode: OVERWRITE }

pipelines:
  name: { source: tx, sink: out1 }
  pipe2: { source: tx, sink: out2 }
  pipe3: { source: tx, sink: out3 }
